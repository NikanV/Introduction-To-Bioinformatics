{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project of Introduction to Bioinformatics\n",
    "\n",
    "## Find The Imposter - Deciphering Mysterious Sequences\n",
    "\n",
    "#### TA: Javad Razi (j.razi@outlook.com)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Description: The Genomic Detective - Delving into Avian DNA with Galaxy\n",
    "\n",
    "### Overview\n",
    "\n",
    "Welcome to an exploratory journey into the world of bioinformatics, where we will delve into the DNA of flying species. This project presents a unique opportunity to unravel a genomic mystery using Galaxy, a sophisticated yet user-friendly bioinformatics platform. Your mission is to assemble a genome from short-read sequences, revealing insights into a specific DNA sequence found in various avian species. Along the way, you'll learn to navigate the complexities of genome assembly and conduct detailed BLAST searches, piecing together a puzzle millions of years in the making. \n",
    "\n",
    "### Objectives and Workflow\n",
    "\n",
    "1. **Introduction and Setup with Galaxy:**\n",
    "   - Start by exploring the Galaxy platform, designed for bioinformatics analysis. You can find a comprehensive introduction and a step-by-step guide on how to use Galaxy, including how to set up your work environment and get data into Galaxy, at the [Galaxy Project Training Network](https://training.galaxyproject.org/). This resource provides a hands-on introduction to Genomics and Galaxy, covering basic aspects like creating a new history and using the Get Data toolbox.\n",
    "\n",
    "2. **Genome Assembly:**\n",
    "   - For learning about genome assembly methods, the [Galaxy Project Training Network](https://training.galaxyproject.org/) offers a variety of resources and guides. This site provides access to a wide range of learning materials, helping users to understand the intricacies of genome assembly within the Galaxy platform.\n",
    "\n",
    "3. **Performing BLAST Searches:**\n",
    "   - To understand how to perform BLAST searches using Galaxy, the NCBI BLAST User Guide remains a crucial resource. You can access it at [NCBI's BLAST User Guide](https://www.ncbi.nlm.nih.gov/books/NBK279690/). This guide offers detailed instructions and insights into using BLAST for sequence comparison and analysis.\n",
    "\n",
    "4. **Comparative Genomics and Analysis:**\n",
    "   - Compare your findings against existing genomic data. This comparative analysis will help you shed light on the unique aspects of your assembled sequence and its significance in avian genetics.\n",
    "\n",
    "### Specific Deliverables\n",
    "\n",
    "- **Complete Code:** Submit all the code you used for assembling the genome, performing BLAST searches, and further analysis. Ensure your code is well-commented and organized for clarity.\n",
    "- **Assembled Genome Fasta File:** Provide the fasta file of the assembled genome. This should be the direct output of your assembly process.\n",
    "- **BLAST Results CSV File:** Include a CSV file with the results from your BLAST searches. This file should contain detailed information about any genomic matches found.\n",
    "- **Detailed Interpretation:** At the end of your notebook, include a thorough interpretation of your findings. Discuss the significance of the sequence within the avian genome, any similarities or differences with sequences in other species, and the potential implications of these results. Your interpretation should be grounded in the data analysis conducted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bioblend (1.2.0) is installed\n",
      "biopython (1.81) is installed\n",
      "pandas (2.1.2) is installed\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import subprocess\n",
    "import pkg_resources\n",
    "\n",
    "def install(package):\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "\n",
    "REQUIRED_PACKAGES = [\n",
    "    'bioblend',\n",
    "    'biopython',\n",
    "    'pandas'\n",
    "]\n",
    "\n",
    "for package in REQUIRED_PACKAGES:\n",
    "    try:\n",
    "        dist = pkg_resources.get_distribution(package)\n",
    "        print('{} ({}) is installed'.format(dist.key, dist.version))\n",
    "    except pkg_resources.DistributionNotFound:\n",
    "        print('{} is NOT installed'.format(package))\n",
    "        install(package)\n",
    "        print('{} was successfully installed.'.format(package))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Assembling Using Galaxy\n",
    "\n",
    "#### Option 1: Python Notebook\n",
    "\n",
    "Finish this section of notebook to assemble a genome from a fasta file with short-read sequences.\n",
    "\n",
    "#### Option 2: Galaxy Web Interface\n",
    "\n",
    "Alternatively, you can use the Galaxy web interface at usegalaxy.org to complete the assembly. This approach allows you to experience the ease and efficiency of Galaxy's web-based tools.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv(dotenv_path='../../.env')\n",
    "\n",
    "# You can create your API key by registering at usegalaxy website, and from user settings section. \n",
    "# It is recommended that you store this key as an environment variable, and not expose it!\n",
    "api_key = os.getenv('GALAXY_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bioblend.galaxy\n",
    "\n",
    "# Initialize Galaxy instance\n",
    "gi = bioblend.galaxy.GalaxyInstance(url='https://usegalaxy.org', key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'outputs': [{'id': 'f9cad7b01a4721350e0bfd217803b9b1',\n",
       "   'hda_ldda': 'hda',\n",
       "   'uuid': '404cda10-b9e8-49a7-9639-581d30dd52e7',\n",
       "   'hid': 1,\n",
       "   'file_ext': 'auto',\n",
       "   'peek': None,\n",
       "   'model_class': 'HistoryDatasetAssociation',\n",
       "   'name': 'short_reads.fasta',\n",
       "   'deleted': False,\n",
       "   'purged': False,\n",
       "   'visible': True,\n",
       "   'state': 'queued',\n",
       "   'history_content_type': 'dataset',\n",
       "   'file_size': 0,\n",
       "   'create_time': '2024-02-03T10:41:41.243804',\n",
       "   'update_time': '2024-02-03T10:41:41.287326',\n",
       "   'data_type': 'galaxy.datatypes.data.Data',\n",
       "   'genome_build': '?',\n",
       "   'validated_state': 'unknown',\n",
       "   'validated_state_message': None,\n",
       "   'misc_info': None,\n",
       "   'misc_blurb': None,\n",
       "   'tags': [],\n",
       "   'history_id': '29f5f1b44823c2b8',\n",
       "   'metadata_dbkey': '?',\n",
       "   'output_name': 'output0'}],\n",
       " 'output_collections': [],\n",
       " 'jobs': [{'model_class': 'Job',\n",
       "   'id': 'bbd44e69cb8906b53dfa3cf21f92fa55',\n",
       "   'state': 'new',\n",
       "   'exit_code': None,\n",
       "   'update_time': '2024-02-03T10:41:41.376834',\n",
       "   'create_time': '2024-02-03T10:41:41.325859',\n",
       "   'galaxy_version': '23.2',\n",
       "   'tool_id': '__DATA_FETCH__',\n",
       "   'history_id': '29f5f1b44823c2b8'}],\n",
       " 'implicit_collections': [],\n",
       " 'produces_entry_points': False}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Upload the fasta file to Galaxy\n",
    "fasta_path = './dataset/short_reads.fasta'\n",
    "fasta_hist = gi.histories.create_history(name=\"FindTheImposterTask_Fasta\")\n",
    "fasta_dict = gi.tools.upload_file(fasta_path, fasta_hist['id'], type='fasta')\n",
    "\n",
    "fasta_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to run the assembly tool: Unexpected HTTP status code: 400: {\"err_msg\": \"parameter 'input': specify a dataset of the required format / build for parameter\", \"err_code\": 400008, \"err_data\": {\"pool|inputs|input\": \"parameter 'input': specify a dataset of the required format / build for parameter\"}, \"param_errors\": {\"pool|inputs|input\": {\"message\": \"parameter 'input': specify a dataset of the required format / build for parameter\", \"message_suffix\": \"specify a dataset of the required format / build for parameter\", \"parameter_name\": \"input\"}}}\n",
      "Failed to run the assembly tool: Unexpected HTTP status code: 400: {\"err_msg\": \"parameter 'input': specify a dataset of the required format / build for parameter\", \"err_code\": 400008, \"err_data\": {\"pool|inputs|input\": \"parameter 'input': specify a dataset of the required format / build for parameter\"}, \"param_errors\": {\"pool|inputs|input\": {\"message\": \"parameter 'input': specify a dataset of the required format / build for parameter\", \"message_suffix\": \"specify a dataset of the required format / build for parameter\", \"parameter_name\": \"input\"}}}\n",
      "Failed to run the assembly tool: Unexpected HTTP status code: 400: {\"err_msg\": \"parameter 'input': specify a dataset of the required format / build for parameter\", \"err_code\": 400008, \"err_data\": {\"pool|inputs|input\": \"parameter 'input': specify a dataset of the required format / build for parameter\"}, \"param_errors\": {\"pool|inputs|input\": {\"message\": \"parameter 'input': specify a dataset of the required format / build for parameter\", \"message_suffix\": \"specify a dataset of the required format / build for parameter\", \"parameter_name\": \"input\"}}}\n",
      "Failed to run the assembly tool: Unexpected HTTP status code: 400: {\"err_msg\": \"parameter 'input': specify a dataset of the required format / build for parameter\", \"err_code\": 400008, \"err_data\": {\"pool|inputs|input\": \"parameter 'input': specify a dataset of the required format / build for parameter\"}, \"param_errors\": {\"pool|inputs|input\": {\"message\": \"parameter 'input': specify a dataset of the required format / build for parameter\", \"message_suffix\": \"specify a dataset of the required format / build for parameter\", \"parameter_name\": \"input\"}}}\n",
      "Failed to run the assembly tool: Unexpected HTTP status code: 400: {\"err_msg\": \"parameter 'input': specify a dataset of the required format / build for parameter\", \"err_code\": 400008, \"err_data\": {\"pool|inputs|input\": \"parameter 'input': specify a dataset of the required format / build for parameter\"}, \"param_errors\": {\"pool|inputs|input\": {\"message\": \"parameter 'input': specify a dataset of the required format / build for parameter\", \"message_suffix\": \"specify a dataset of the required format / build for parameter\", \"parameter_name\": \"input\"}}}\n",
      "Failed to run the assembly tool: Unexpected HTTP status code: 400: {\"err_msg\": \"parameter 'input': specify a dataset of the required format / build for parameter\", \"err_code\": 400008, \"err_data\": {\"pool|inputs|input\": \"parameter 'input': specify a dataset of the required format / build for parameter\"}, \"param_errors\": {\"pool|inputs|input\": {\"message\": \"parameter 'input': specify a dataset of the required format / build for parameter\", \"message_suffix\": \"specify a dataset of the required format / build for parameter\", \"parameter_name\": \"input\"}}}\n",
      "Assembly job submitted\n"
     ]
    }
   ],
   "source": [
    "# Identify and Prepare the Assembly Tool\n",
    "\n",
    "# The only tool that we found suitable for this task is Trinity, which is a popular tool for de novo assembly of RNA-seq data.\n",
    "# Other tools where either for pre and post processing of the data, or for other quality controls.\n",
    "assembly_tool = gi.tools.get_tools(name='Trinity')[0]\n",
    "\n",
    "assembly_params = {\n",
    "    # Using the default mode to maintain a balance between different factors like speed, accuracy, etc.\n",
    "    'mode_sel': 'default',\n",
    "    \n",
    "    # We only want to perform the assembly, and not other analysis.\n",
    "    'operation_mode': 'assembly_only',\n",
    "}\n",
    "\n",
    "# Run the Assembly Tool\n",
    "while True:\n",
    "    try:\n",
    "        assembly_dict = gi.tools.run_tool(fasta_hist['id'], assembly_tool['id'], assembly_params)\n",
    "        print(f\"Assembly job submitted\")\n",
    "        break\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to run the assembly tool: {e}\")\n",
    "\n",
    "# Wait for the assembly job to complete\n",
    "assembly_dict = gi.jobs.wait_for_job(job_id=assembly_dict['jobs'][0]['id'], maxwait=120, interval=5, check=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_class': 'Job',\n",
       " 'id': 'bbd44e69cb8906b5261a009a270a6fea',\n",
       " 'state': 'ok',\n",
       " 'exit_code': 0,\n",
       " 'update_time': '2024-02-03T10:42:29.555475',\n",
       " 'create_time': '2024-02-03T10:41:54.919274',\n",
       " 'galaxy_version': '23.2',\n",
       " 'command_version': None,\n",
       " 'copied_from_job_id': None,\n",
       " 'tool_id': 'toolshed.g2.bx.psu.edu/repos/iuc/trinity/trinity/2.9.1+galaxy2',\n",
       " 'history_id': '29f5f1b44823c2b8',\n",
       " 'params': {'pool': '{\"__current_case__\": 0, \"inputs\": {\"__current_case__\": 0, \"input\": {\"values\": [{\"id\": 122369565, \"src\": \"hda\"}]}, \"paired_or_single\": \"single\", \"strand\": {\"__current_case__\": 0, \"is_strand_specific\": false}}, \"pool_mode\": \"Yes\"}',\n",
       "  'norm': 'true',\n",
       "  'additional_params': '{\"guided\": {\"__current_case__\": 0, \"is_guided\": \"no\"}, \"long_reads\": null, \"min_contig_length\": \"200\", \"min_kmer_cov\": \"1\"}',\n",
       "  'chromInfo': '\"/cvmfs/data.galaxyproject.org/managed/len/ucsc/?.len\"',\n",
       "  'dbkey': '\"?\"',\n",
       "  '__input_ext': '\"fasta\"'},\n",
       " 'inputs': {'pool|inputs|input': {'id': 'f9cad7b01a4721350e0bfd217803b9b1',\n",
       "   'src': 'hda',\n",
       "   'uuid': '404cda10-b9e8-49a7-9639-581d30dd52e7'},\n",
       "  'pool|inputs|input1': {'id': 'f9cad7b01a4721350e0bfd217803b9b1',\n",
       "   'src': 'hda',\n",
       "   'uuid': '404cda10-b9e8-49a7-9639-581d30dd52e7'}},\n",
       " 'outputs': {'assembled_transcripts': {'id': 'f9cad7b01a472135c5182f04a3303a25',\n",
       "   'src': 'hda',\n",
       "   'uuid': 'fe34bed2-964c-4ed6-9eb5-0f634c7bf675'},\n",
       "  'gene_to_trans': {'id': 'f9cad7b01a4721352bf189faab7b5f31',\n",
       "   'src': 'hda',\n",
       "   'uuid': '6cea4971-9093-407b-8f5a-f83a9580009a'}},\n",
       " 'output_collections': {},\n",
       " 'command_line': 'if [ -z \"$GALAXY_MEMORY_MB\" ] ; then GALAXY_MEMORY_GB=1 ; else GALAXY_MEMORY_GB=$((GALAXY_MEMORY_MB / 1024)) ; fi ;  if [ ! -z \"$TRINITY_SCRATCH_DIR\" ] ; then workdir=`pwd` ; scratchfolder=$(mktemp -d -p \"$TRINITY_SCRATCH_DIR\"); emptyfolder=$(mktemp -d -p \"$TRINITY_SCRATCH_DIR\"); cd \"$scratchfolder\" ; fi ;  ln -s \\'/corral4/main/objects/4/0/4/dataset_404cda10-b9e8-49a7-9639-581d30dd52e7.dat\\' input0.fasta &&  Trinity --no_version_check  --single \\'input0.fasta\\' --seqType fa    --min_contig_length 200  --min_kmer_cov 1  --CPU ${GALAXY_SLOTS:-4} --max_memory ${GALAXY_MEMORY_GB:-1}G --bflyHeapSpaceMax ${GALAXY_MEMORY_GB:-1}G --bfly_opts \\'-V 10 --stderr\\'   &&  if [ ! -z \"$TRINITY_SCRATCH_DIR\" ] ; then mkdir -p \"$workdir/trinity_out_dir\"; cp -p trinity_out_dir/Trinity* \"$workdir/trinity_out_dir\"; cd \"$TRINITY_SCRATCH_DIR\"; rsync -a --delete \"$emptyfolder/\" \"$scratchfolder/\"; rmdir \"$emptyfolder\" \"$scratchfolder/\"; cd \"$workdir\"; fi ;'}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assembly_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The assembled genome was successfully downloaded and was saved in the dataset directory\n"
     ]
    }
   ],
   "source": [
    "# Download the assembled genome from Galaxy. You can use the `download_dataset` method. A FASTA file, containing assembly\n",
    "# of the whole sequence is what we expect here. \n",
    "assembled_genome_id = None\n",
    "\n",
    "# Finding the assembled genome file id\n",
    "hist_id = fasta_hist['id']\n",
    "hist_datasets = gi.histories.show_history(hist_id, contents=True)\n",
    "\n",
    "for dataset in hist_datasets:\n",
    "    if \"Assembled Transcripts\" in dataset['name']:\n",
    "        assembled_genome_id = dataset['id']\n",
    "        break\n",
    "\n",
    "# Now download the dataset via its APIs\n",
    "try:\n",
    "    gi.datasets.download_dataset(assembled_genome_id, file_path='./dataset/')\n",
    "    print(\"The assembled genome was successfully downloaded and was saved in the dataset directory\")\n",
    "except Exception as e:\n",
    "    print(f\"Failed to download the assembled genome: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Using BLAST to Query The Assembled Sequence\n",
    "\n",
    "In this part of the notebook, you will utilize the NCBI BLAST API to analyze the genome sequence you've assembled. This involves integrating the API into your notebook, submitting your sequence for BLAST querying, and then meticulously examining the results. Your focus will be on identifying similarities or unique traits in the sequence compared to others in the NCBI database, particularly exploring its relationship with known sequences in various species. This step is crucial for understanding the evolutionary and biological significance of your assembled genome.\n",
    "\n",
    "**Note**: Unlike the previous section, for this one, you must deliver the full code in the notebook. Doing this part using website will not be graded. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from Bio.Blast import NCBIWWW\n",
    "from Bio.Blast import NCBIXML\n",
    "from collections import defaultdict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the assembled genome\n",
    "with open('./outputs/assembled_genome.fasta', 'r') as file:\n",
    "    assembled_genome = file.read()\n",
    "\n",
    "assembled_genome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio.Blast import NCBIWWW\n",
    "\n",
    "# Perform the BLAST query, filtering for eukaryotes\n",
    "\n",
    "### TODO ###\n",
    "result_handle = NCBIWWW.qblast(program=None, \n",
    "                               database=None, \n",
    "                               sequence=None, \n",
    "                               entrez_query=None, # Only filter Eucaryotes. Hint: You can do this by giving their taxonomy id.\n",
    "                               hitlist_size=100, \n",
    "                               word_size=16)\n",
    "### TODO ###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object parse at 0x0000020D4D9B1540>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Bio.Blast import NCBIXML\n",
    "\n",
    "blast_records = NCBIXML.parse(result_handle)\n",
    "\n",
    "blast_records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from Bio import Entrez\n",
    "\n",
    "# Set your email here for Entrez\n",
    "Entrez.email = \"your.email@example.com\"\n",
    "\n",
    "def fetch_taxonomy_info(accession):\n",
    "    \"\"\"\n",
    "    Fetch taxonomy information using Entrez for a given accession number.\n",
    "    \"\"\"\n",
    "    handle = Entrez.efetch(db=\"nucleotide\", id=accession, retmode=\"xml\")\n",
    "    records = Entrez.read(handle)\n",
    "    \n",
    "    ### TODO ###\n",
    "    \n",
    "    taxonomy = None\n",
    "    species = None \n",
    "    \n",
    "    ### TODO ### \n",
    "    \n",
    "    return taxonomy, species\n",
    "\n",
    "\n",
    "def parse_blast_results():\n",
    "    \"\"\"\n",
    "    Parse BLAST results and extract relevant information including taxonomy.\n",
    "    \"\"\"\n",
    "    blast_results = []\n",
    "\n",
    "    for record in blast_records:\n",
    "        for alignment in record.alignments:\n",
    "            accession = alignment.accession\n",
    "            taxonomy, species = fetch_taxonomy_info(accession)\n",
    "            for hsp in alignment.hsps:\n",
    "                # These fields are required in your submission\n",
    "                blast_results.append({\n",
    "                    'query_id': record.query_id,\n",
    "                    'alignment_title': alignment.title,\n",
    "                    'e_value': hsp.expect,\n",
    "                    'identity': hsp.identities,\n",
    "                    'accession': accession,\n",
    "                    'taxonomy': taxonomy,\n",
    "                    'species': species\n",
    "                })\n",
    "    return blast_results\n",
    "\n",
    "\n",
    "blast_results = parse_blast_results()\n",
    "df = pd.DataFrame(blast_results)\n",
    "df.to_csv('./outputs/blast_results_with_taxonomy.csv', index=False)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of The Results\n",
    "\n",
    "### Drawing Your Own Conclusions\n",
    "\n",
    "Now that you have completed the BLAST search, a fascinating part of your journey begins – interpreting the data. This stage is where your critical thinking and creativity come into play. From now on, the rest of the notebook will be about whatever you want it to be. Any path that leads to meaningful insights about the data and provides a solid conclusion for the task is acceptable. Let's explore some possible directions:\n",
    "\n",
    "1. **Species-Specific Patterns:** Examine if the sequence is found exclusively or predominantly in certain species. What could this suggest about its evolution and adaptation? While the focus is not on finding a 'correct' answer, pondering this aspect can lead to interesting hypotheses about species-specific interactions.\n",
    "\n",
    "2. **Functional Insights:** Reflect on the potential roles this sequence might play within the genomes where it's found. Could it be integral to certain biological functions, or a legacy of ancient genomic events?\n",
    "\n",
    "3. **Comparative Genomics:** Compare your findings with sequences in other species. Notice any striking similarities or differences? These comparisons could shed light on the sequence's evolutionary journey.\n",
    "\n",
    "4. **Ecological and Environmental Context:** Consider the ecological and environmental factors that might influence the distribution and evolution of this sequence. How might habitat or lifestyle of the species play a role in its presence or absence?\n",
    "\n",
    "### Additional Tips and Encouragement\n",
    "\n",
    "This project is more about the learning journey and less about achieving perfect results. Here are some additional pointers:\n",
    "\n",
    "1. **Deep Dives:** Encourage yourself to explore the data thoroughly. Use various bioinformatics tools to gain a holistic understanding.\n",
    "\n",
    "2. **Creative Visualization:** Craft visual representations of your analysis. Effective use of charts or infographics can provide insightful perspectives.\n",
    "\n",
    "3. **Open-Ended Exploration:** Feel free to extend your analysis in directions you find intriguing. This could include phylogenetic studies or exploring the ecological aspects of the sequence.\n",
    "\n",
    "Remember, this project is designed to be a learning experience. We don't expect you to uncover all the answers but rather to engage thoughtfully with the data and enjoy the process of discovery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO ###"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
